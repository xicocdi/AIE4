{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ü§ù Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ü§ù Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ü§ù Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chainlit 1.1.306 requires packaging<24.0,>=23.1, but you have packaging 24.1 which is incompatible.\n",
            "ragas 0.1.20 requires langchain-core<0.3, but you have langchain-core 0.3.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-09-29 17:32:54--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8001::154, 2606:50c0:8000::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: ‚Äòjohn_wick_1.csv‚Äô\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2024-09-29 17:32:54 (15.2 MB/s) - ‚Äòjohn_wick_1.csv‚Äô saved [19628/19628]\n",
            "\n",
            "--2024-09-29 17:32:54--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8000::154, 2606:50c0:8002::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: ‚Äòjohn_wick_2.csv‚Äô\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-29 17:32:55 (51.3 MB/s) - ‚Äòjohn_wick_2.csv‚Äô saved [14747/14747]\n",
            "\n",
            "--2024-09-29 17:32:55--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: ‚Äòjohn_wick_3.csv‚Äô\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-29 17:32:55 (47.5 MB/s) - ‚Äòjohn_wick_3.csv‚Äô saved [13888/13888]\n",
            "\n",
            "--2024-09-29 17:32:55--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: ‚Äòjohn_wick_4.csv‚Äô\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-29 17:32:56 (67.6 MB/s) - ‚Äòjohn_wick_4.csv‚Äô saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2024, 9, 27, 20, 23, 0, 196035)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the reviews provided.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, an ex-hitman comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. The story is filled with violent action, shootouts, and breathtaking fights as John Wick unleashes a maelstrom of destruction against those who come after him. The plot revolves around his relentless vendetta and the consequences of his actions in the criminal underworld.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Opinions on John Wick seem to vary among viewers. Some people really enjoyed it and praised the action sequences and Keanu Reeves' performance, while others found it lacking in plot and substance. It ultimately depends on individual preferences.\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'No reviews have a rating of 10.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the action is beautifully choreographed, the setup is surprisingly emotional for an action flick, and Keanu Reeves delivers a fantastic performance. It is highly recommended for action movie fans.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_cohere in /opt/anaconda3/lib/python3.12/site-packages (0.3.0)\n",
            "Requirement already satisfied: cohere<6.0,>=5.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (5.10.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (0.3.6)\n",
            "Requirement already satisfied: langchain-experimental>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (0.3.2)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (2.2.3)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (2.9.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.34.142)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.9.5)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.27.0)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.4.0)\n",
            "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.19.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.0.20240622)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (0.1.128)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/xico/.local/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3.0->langchain_cohere) (8.3.0)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-experimental>=0.3.0->langchain_cohere) (0.3.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.3->langchain_cohere) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/xico/.local/lib/python3.12/site-packages (from pandas>=1.4.3->langchain_cohere) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.3->langchain_cohere) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.3->langchain_cohere) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_cohere) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.142 in /opt/anaconda3/lib/python3.12/site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (1.34.142)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (0.10.2)\n",
            "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.5)\n",
            "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_cohere) (2.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.5.14)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.3.1)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (2.5.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_cohere) (3.10.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/xico/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain_cohere) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain_cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.0.0->cohere<6.0,>=5.5.6->langchain_cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/anaconda3/lib/python3.12/site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (0.23.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.9.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.9.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (2024.3.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (4.66.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (0.3.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental>=0.3.0->langchain_cohere) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain_cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.128)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/xico/.local/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain) (2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic==1.10.7 in /opt/anaconda3/lib/python3.12/site-packages (1.10.7)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic==1.10.7) (4.12.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pydantic==1.10.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick.'"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick 2, after resolving his issues with the Russian mafia, John Wick returns home but is visited by the mobster Santino D'Antonio who asks him to kill his sister Gianna D'Antonio in Rome. When John accomplishes this task, Santino puts a seven-million dollar contract on him, leading to professional killers coming after him. Wick promises to kill Santino who is not protected by his marker anymore.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, people generally liked John Wick based on the reviews provided, which praised the film for its action sequences, Keanu Reeves' performance, and overall entertainment value.\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm sorry, there are no reviews with a rating of 10 in the provided context.\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, a retired assassin named John Wick comes out of retirement when someone kills his dog and steals his car. He goes on a rampage of carnage to seek revenge and settle old debts by helping take over the Assassin's Guild. The movie involves John Wick flying around to Italy, Canada, and Manhattan, killing numerous assassins along the way.\""
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/7f/h3rrllhd5y55j96mk0sh0cfm0000gn/T/ipykernel_75035/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People's opinions about John Wick seem to vary. Some really enjoy the series, while others have criticized certain aspects of the movies.\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". The URL to that review is: \\'/review/rw4854296/?ref_=tt_urv\\''"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick 2, John Wick, a retired assassin, is forced back into action when someone steals his car, leading to a lot of carnage. He is then called on to pay off an old debt by helping Ian McShane take over the Assassin's Guild by traveling to Italy, Canada, and Manhattan and killing many assassins.\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People generally liked John Wick based on the reviews provided. The action, choreography, and Keanu Reeves' performance were highly praised. The film was described as fun, stylish, and engaging, with many reviewers recommending it to action movie fans. Some reviews mentioned that the first film in the series was special and different from typical action films, while others appreciated the unique world-building and intense action sequences. Overall, the majority of reviews were positive, highlighting John Wick's appeal to action fans.\""
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, an ex-hitman comes out of retirement to seek vengeance on the gangsters who killed his dog and took everything from him. The story is filled with violent action, shootouts, and breathtaking fights as John Wick unleashes destruction against those who come after him.'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People generally liked John Wick based on the positive reviews provided.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there are reviews with a rating of 10. Here are the URLs to those reviews:\\n1. '/review/rw4854296/?ref_=tt_urv' - A Masterpiece & Brilliant Sequel\\n2. '/review/rw8944843/?ref_=tt_urv' - How Can Anyone Choose to Watch Marvel Over This?\""
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In John Wick, the main character seeks revenge on the people who took something he loved from him. Specifically, in the first movie, they killed his dog and stole his car, leading him to unleash a carefully orchestrated maelstrom of destruction against those who wronged him.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ü§ù Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### üèóÔ∏è Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv(\"/Users/xico/AIE4/Week 7/Day 2/synthetic_jw_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Retriever Evaluation - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "unique_id = uuid4().hex[0:8]\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"LangSmith AIM Retriever Eval - {unique_id}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass('Enter your LangSmith API key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is a review with a rating of 10. Here is the URL to that review: '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "\n",
        "def run_evaluation(retrieval_chain):\n",
        "    answers = []\n",
        "    contexts = []\n",
        "\n",
        "    for question in test_questions:\n",
        "        response = naive_retrieval_chain.invoke({\"question\" : question})\n",
        "        answers.append(response[\"response\"].content)\n",
        "        contexts.append([context.page_content for context in response[\"context\"]])\n",
        "    response_dataset = Dataset.from_dict({\n",
        "        \"question\" : test_questions,\n",
        "        \"answer\" : answers,\n",
        "        \"contexts\" : contexts,\n",
        "        \"ground_truth\" : test_groundtruths\n",
        "    })\n",
        "    return evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = naive_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "baseline_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What makes the set pieces in John Wick: Chapter 4 stand out compared to the previous movies in the franchise?',\n",
              " 'answer': 'The set pieces in John Wick: Chapter 4 stand out compared to the previous movies in the franchise due to their infusion of creativity that had not been seen before in the series.',\n",
              " 'contexts': [\": 18\\nReview: Ever since the original John Wick, the franchise has set a standard of what action in Hollywood should be. Thanks to Chad Stahelski and Keanu Reeve's knowledge of the technical aspects of shooting action, they've been able to deliver expertly choreographed, shot, and edited action films that are now the go to as examples of great action filmmaking. And so, the expectations for the fourth film were fairly high, especially as it became more apparent this was not only the culmination of everything before it, but a whopping 169 minutes long. Rest assured, however, that it delivers in spades. Everything we have come to know and love is here, but with an infusion of creativity like we haven't seen from the franchise yet.\",\n",
              "  \": 19\\nReview: John Wick: Chapter 4 picks up where Chapter 3: Parabellum left off. As has been the tradition in the sequels to this beloved martial arts action franchise the action starts from the very inception of the film's opening, and lasts until the curtain falls. JW4 is no exception to that rule. What it does do is improve on the prior installment, and solidify Keanu Reeves as the greatest martial arts action star of all time. If you don't accept that notion, then you must accept the fact that it solidifies Reeves and Director, Chad Stahelski, as the greatest martial arts action pairing of modern times.\",\n",
              "  \": 14\\nReview: By now you know what to expect from a John Wick movie. I thought the franchise was losing a little momentum in chapter 3 so I was worried this could be disappointing. It's not. It's even more on steroids than any Wick before! Even close to 3 hours it doesn't feel to long which is very special for a action movie. This franchise has set new standards. If anybody says a movie is good like John Wick, it better f'n be! The set pieces as everyone mentioned before are really insane this time. The Tokyo sceney with illuminated cherry blossoms was beautiful. The only super illogical thing that bothered me was that nobody flinched at the nightclub, eventually they did but after a whole 10 minute beatdown through the whole club, but then again it's a shady nightclub for high table people. If you liked the first three movies, get your ass to the cinema. Yeah.\",\n",
              "  ': 19\\nReview: The inevitable third chapter of the JOHN WICK franchise continues on a high with the same quality as the last. In fact, this may just pip that one to the post to be the best JOHN WICK yet. The pacing is spot on and the plotting is measured by a huge amount of action sequences, all of which fizz and crackle with skill and energy. The movie hits the ground running as Keanu faces off with a hulking character in a library and then Triads in a weapon shop, but what really amazes here is the sheer inventiveness of the non-repetitive action. There are horse and motorbike chases, a Moroccan brawl with fighting dogs, alongside the massive action of the climax. There also seems to be a greater emphasis on hand-to-hand combat, featuring the likes of RAID actors and old-timer Mark Dacascos, which is a real pleasure as the choreography is top-notch. In terms of sheer enjoyment, this is a film hard to beat, and to criticise it at all is unnecessary. Bring on the fourth!',\n",
              "  ': 3\\nReview: John wick has a very simple revenge story. It can be summarized as \"Keanu gets angry and shoots bad guys\" but what makes it special? Directed by Chad Stahelski who\\'s a stunt specialist boy does it show because the main selling point in the film are some real virtuoso action sequences, well made choreographies. Unlike today\\'s action movies, it doesn\\'t use quick-cuts or shaky cameras actually see what\\'s going on.',\n",
              "  ': 24\\nReview: John Wick: Chapter 4 is almost three hours of Keanu Reeves engaged in a gunfight, bookended with meaningless dialog-in-place-of-plot, and a lot of people being thrown down stairs. Of all the \"Wick\" movies, this is clearly the weakest one yet. Was anything added to the overall Wick-universe narrative? No. Did we see a whole lot of inconsequential people die? Yes. Did Keanu Reeves say \"yeah\" a lot? Yes.',\n",
              "  ': 0\\nReview: It is 5 years since the first John Wick film - one that took me by surprise by how silly it was as a narrative, but yet how well it delivered action sequences. The second film was only 2 years ago, and it raised the stakes and went from a man seeking revenge on another group of people, into one where the world was filled with assassins, popping up from everywhere all the time. I remember ending that film feeling like it had gone too far but that the third would probably do more of that. True enough, Parabellum (\"prepare for war\") sees the whole world filled with assassins, and a huge administrative system around them - but yet the whole lot of them can\\'t seem to cause John Wick too much trouble. As with the first film, this expands the world more than it can bear, and although it looks cool at times, the world makes no sense whatsoever and it hurts the film the more it relies on it (which it does as it expands it).',\n",
              "  ': 4\\nReview: \"John Wick: Chapter 2\" (2017 release; 122 min.) continues the \\'adventures\\' of former (?) hit man John Wick. As the movie opens, we are immediately thrown in the middle of a car vs. bike chase, and next thing we know, we find our man retrieving his beloved Mustang from a chop shop in NYC, but not without cars flying about, and dozens of dead or wounded bodies. And that\\'s all in the pre-opening credits! As the story unfolds, Wick, who wants \"out, is nevertheless forced back \"in\" when an Italian baddie calls in a favor and Wick has no choice but to accept. To tell you more of the plot would spoil your viewing experience, you\\'ll just have to see for yourself how it all plays out.',\n",
              "  \": 20\\nReview: John Wick is something special. It takes as much time setting up elaborate action sequences as it does the world with which it all takes place in. And what a world it is. It reminds me of Millers Crossing and it is cooler than any other recent attempt at noir. We are shown a criminal underworld where, if you are connected, many powerful people know who you are and show you respect. John Wick was connected but he got out. He is the rare killer who has found peace, and he is grateful for that peace. Some young kids steal that from him and he does what he does best, he wages a one man war against the Russian Mafia. It might sound like the film takes quite a leap but it all makes sense. The motives of John and the people who get in the way of his bullets are all very clear, even if it does come across as rather simple. That's the plot at it's most basic. Then there's the action. The film is directed by Reeve's stuntman from The Matrix, so this guy knows action. There are sequences that flow so smoothly it puts other action films and their quick cuts to shame. Keaunu moves so fluidly throughout the film and comes across as such a natural that the only disappointment is that we have not seen him like this before. Along the way are plenty of character actors, fans of The Matrix and The Wire will recognize a few people then there are more obvious ones like Ian McShane and Willem Dafoe. Everyone seems to be having a good time. That is another plus for this movie. It get's dark at times but overall it is quite fun, not very chipper, but fun. I cannot recommend this movie enough. I believe it is a must see for action fans and for anyone looking for something a bit different from the usual fare.\",\n",
              "  \": 1\\nReview: I'm a fan of the John Wick films. The action sequences are of the highest order and there is quite a bit that feels unique in each action scene. By half way through JW3I started to long for a plot line or a human relationship. There needs to be more to a movie than just fighting.\"],\n",
              " 'ground_truth': 'The answer to given question is not present in context'}"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81a81be7e33343e1b43fa13d834d36f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "baseline_results = evaluate(baseline_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.9265, 'context_precision': 0.7399, 'answer_correctness': 0.6463}"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[: 18\\nReview: Ever since the original John Wi...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.177896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.982143</td>\n",
              "      <td>0.589875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[: 0\\nReview: It is 5 years since the first Jo...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.488889</td>\n",
              "      <td>0.180156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[: 9\\nReview: At first glance, John Wick sound...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.703571</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
              "      <td>The Mission Impossible franchise sets itself a...</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.473502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [: 18\\nReview: Ever since the original John Wi...   \n",
              "1  [: 3\\nReview: John wick has a very simple reve...   \n",
              "2  [: 0\\nReview: It is 5 years since the first Jo...   \n",
              "3  [: 9\\nReview: At first glance, John Wick sound...   \n",
              "4  [: 10\\nReview: Most American action flicks rel...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  The action sequences in the JOHN WICK franchis...   \n",
              "2                                      I don't know.   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4  The Mission Impossible franchise sets itself a...   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...             1.0   \n",
              "1  The action sequences in the JOHN WICK franchis...             1.0   \n",
              "2  The level of violence in the third John Wick f...             1.0   \n",
              "3  Keanu Reeves plays the character John Wick in ...             1.0   \n",
              "4  The Mission Impossible franchise is one of the...             1.0   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.177896  \n",
              "1           0.982143            0.589875  \n",
              "2           0.488889            0.180156  \n",
              "3           0.703571            1.000000  \n",
              "4           0.611111            0.473502  "
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_results_df = baseline_results.to_pandas()\n",
        "baseline_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(baseline_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "baseline_avg_token_df = pd.DataFrame({'BaslineAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BaslineAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BaslineAvgToken\n",
              "0             9022"
            ]
          },
          "execution_count": 254,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_metrics_df = pd.DataFrame(list(baseline_results.items()), columns=['Metric', 'Baseline'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.926471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.739921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.646322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline\n",
              "0      context_recall  0.926471\n",
              "1   context_precision  0.739921\n",
              "2  answer_correctness  0.646322"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = contextual_compression_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "contextual_compression_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a89c03ce06f647a58b8eac5c2c0116f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "contextual_compression_results = evaluate(contextual_compression_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8186, 'context_precision': 0.6217, 'answer_correctness': 0.6331}"
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[- the original John Wick\\n- the franchise\\n- ...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.929085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[- Directed by Chad Stahelski who's a stunt sp...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.501298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[- the third John Wick film\\n- level of violen...</td>\n",
              "      <td>I don't know the specific impact of the level ...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.418889</td>\n",
              "      <td>0.225291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[Keanu Reeves, John Wick, action film, action ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.797222</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[Mission Impossible, - \"Mission Impossible fra...</td>\n",
              "      <td>I'm sorry, I don't have specific information a...</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.219323</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [- the original John Wick\\n- the franchise\\n- ...   \n",
              "1  [- Directed by Chad Stahelski who's a stunt sp...   \n",
              "2  [- the third John Wick film\\n- level of violen...   \n",
              "3  [Keanu Reeves, John Wick, action film, action ...   \n",
              "4  [Mission Impossible, - \"Mission Impossible fra...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  The action sequences in the JOHN WICK franchis...   \n",
              "2  I don't know the specific impact of the level ...   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4  I'm sorry, I don't have specific information a...   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...        1.000000   \n",
              "1  The action sequences in the JOHN WICK franchis...        1.000000   \n",
              "2  The level of violence in the third John Wick f...        1.000000   \n",
              "3  Keanu Reeves plays the character John Wick in ...        1.000000   \n",
              "4  The Mission Impossible franchise is one of the...        0.333333   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.929085  \n",
              "1           0.741667            0.501298  \n",
              "2           0.418889            0.225291  \n",
              "3           0.797222            1.000000  \n",
              "4           0.200000            0.219323  "
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_results_df = contextual_compression_results.to_pandas()\n",
        "contextual_compression_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(contextual_compression_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "contextual_compresion_avg_token_df = pd.DataFrame({'CCAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CCAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CCAvgToken\n",
              "0        3898"
            ]
          },
          "execution_count": 252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compresion_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {},
      "outputs": [],
      "source": [
        "contextual_compression_metrics_df = pd.DataFrame(list(contextual_compression_results.items()), columns=['Metric', 'ContextualCompression'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ContextualCompression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.818627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.621724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.633126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  ContextualCompression\n",
              "0      context_recall               0.818627\n",
              "1   context_precision               0.621724\n",
              "2  answer_correctness               0.633126"
            ]
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = multi_query_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_query_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb6b4098a8004375aeff0e209fe3329c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "multi_query_results = evaluate(multi_query_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.9118, 'context_precision': 0.6728, 'answer_correctness': 0.6522}"
            ]
          },
          "execution_count": 185,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[: 19\\nReview: John Wick: Chapter 4 picks up w...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.924665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[: 3\\nReview: John wick has a very simple reve...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.847470</td>\n",
              "      <td>0.664750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[: 2\\nReview: The first three John Wick films ...</td>\n",
              "      <td>I don't know the specific impact of the level ...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.607384</td>\n",
              "      <td>0.232388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[: 9\\nReview: At first glance, John Wick sound...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.806602</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.361774</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [: 19\\nReview: John Wick: Chapter 4 picks up w...   \n",
              "1  [: 3\\nReview: John wick has a very simple reve...   \n",
              "2  [: 2\\nReview: The first three John Wick films ...   \n",
              "3  [: 9\\nReview: At first glance, John Wick sound...   \n",
              "4  [: 10\\nReview: Most American action flicks rel...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  The action sequences in the JOHN WICK franchis...   \n",
              "2  I don't know the specific impact of the level ...   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...             1.0   \n",
              "1  The action sequences in the JOHN WICK franchis...             1.0   \n",
              "2  The level of violence in the third John Wick f...             1.0   \n",
              "3  Keanu Reeves plays the character John Wick in ...             1.0   \n",
              "4  The Mission Impossible franchise is one of the...             1.0   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.924665  \n",
              "1           0.847470            0.664750  \n",
              "2           0.607384            0.232388  \n",
              "3           0.806602            1.000000  \n",
              "4           0.791667            0.361774  "
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_results_df = multi_query_results.to_pandas()\n",
        "multi_query_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(multi_query_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "multi_query_avg_token_df = pd.DataFrame({'MQAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MQAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MQAvgToken\n",
              "0       10951"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_query_metrics_df = pd.DataFrame(list(multi_query_results.items()), columns=['Metric', 'MultiQuery'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>MultiQuery</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.911765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.672826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.652217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  MultiQuery\n",
              "0      context_recall    0.911765\n",
              "1   context_precision    0.672826\n",
              "2  answer_correctness    0.652217"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = parent_document_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_document_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c3409c46ab6463e9ff6c9257798d906",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "parent_document_results = evaluate(parent_document_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.7770, 'context_precision': 0.7475, 'answer_correctness': 0.6293}"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[: 14\\nReview: By now you know what to expect ...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[: 1\\nReview: I'm a fan of the John Wick films...</td>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.347527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[: 14\\nReview: By now you know what to expect ...</td>\n",
              "      <td>Based on the context provided, the level of vi...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.792764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[: 0\\nReview: The best way I can describe John...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
              "      <td>The Mission Impossible franchise sets itself a...</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.686760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [: 14\\nReview: By now you know what to expect ...   \n",
              "1  [: 1\\nReview: I'm a fan of the John Wick films...   \n",
              "2  [: 14\\nReview: By now you know what to expect ...   \n",
              "3  [: 0\\nReview: The best way I can describe John...   \n",
              "4  [: 10\\nReview: Most American action flicks rel...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  Based on the context provided, the level of vi...   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4  The Mission Impossible franchise sets itself a...   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...        1.000000   \n",
              "1  The action sequences in the JOHN WICK franchis...        0.333333   \n",
              "2  The level of violence in the third John Wick f...        1.000000   \n",
              "3  Keanu Reeves plays the character John Wick in ...        1.000000   \n",
              "4  The Mission Impossible franchise is one of the...        1.000000   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.178577  \n",
              "1           1.000000            0.347527  \n",
              "2           0.583333            0.792764  \n",
              "3           1.000000            1.000000  \n",
              "4           1.000000            0.686760  "
            ]
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_results_df = parent_document_results.to_pandas()\n",
        "parent_document_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(parent_document_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "parent_doc_avg_token_df = pd.DataFrame({'PDAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PDAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PDAvgToken\n",
              "0        1350"
            ]
          },
          "execution_count": 248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_doc_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [],
      "source": [
        "parent_document_metrics_df = pd.DataFrame(list(parent_document_results.items()), columns=['Metric', 'ParentDoc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ParentDoc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.776961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.747549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.629344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  ParentDoc\n",
              "0      context_recall   0.776961\n",
              "1   context_precision   0.747549\n",
              "2  answer_correctness   0.629344"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = ensemble_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "ensemble_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82c991f21c3e4b1c9acb4f255f0ca63b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ensemble_results = evaluate(ensemble_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.9167, 'context_precision': 0.6061, 'answer_correctness': 0.6883}"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[: 19\\nReview: John Wick: Chapter 4 picks up w...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[: 1\\nReview: I'm a fan of the John Wick films...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.780953</td>\n",
              "      <td>0.880688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[: 9\\nReview: At first glance, John Wick sound...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.523265</td>\n",
              "      <td>0.638225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[Keanu Reeves, : 0\\nReview: The best way I can...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.756942</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.181780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [: 19\\nReview: John Wick: Chapter 4 picks up w...   \n",
              "1  [: 1\\nReview: I'm a fan of the John Wick films...   \n",
              "2  [: 9\\nReview: At first glance, John Wick sound...   \n",
              "3  [Keanu Reeves, : 0\\nReview: The best way I can...   \n",
              "4  [: 10\\nReview: Most American action flicks rel...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  The action sequences in the JOHN WICK franchis...   \n",
              "2  The level of violence in the third John Wick f...   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4                                      I don't know.   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...             1.0   \n",
              "1  The action sequences in the JOHN WICK franchis...             1.0   \n",
              "2  The level of violence in the third John Wick f...             1.0   \n",
              "3  Keanu Reeves plays the character John Wick in ...             1.0   \n",
              "4  The Mission Impossible franchise is one of the...             1.0   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.176822  \n",
              "1           0.780953            0.880688  \n",
              "2           0.523265            0.638225  \n",
              "3           0.756942            1.000000  \n",
              "4           0.531250            0.181780  "
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18533"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(str(ensemble_results_df.iloc[0].contexts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(ensemble_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "ensemble_avg_token_df = pd.DataFrame({'EnsembleAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EnsembleAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EnsembleAvgToken\n",
              "0             16960"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "ensemble_metrics_df = pd.DataFrame(list(ensemble_results.items()), columns=['Metric', 'Ensemble'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Ensemble</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.606057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.688328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Ensemble\n",
              "0      context_recall  0.916667\n",
              "1   context_precision  0.606057\n",
              "2  answer_correctness  0.688328"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = semantic_retrieval_chain.invoke({\"question\" : question})\n",
        "  answers.append(response['response'].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd540949d1b244799aa0cbdc94a830e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "semantic_results = evaluate(semantic_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8284, 'context_precision': 0.6835, 'answer_correctness': 0.6140}"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>answer</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What makes the set pieces in John Wick: Chapte...</td>\n",
              "      <td>[: 18\\nReview: Ever since the original John Wi...</td>\n",
              "      <td>The set pieces in John Wick: Chapter 4 stand o...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.924168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What sets the action sequences in the JOHN WIC...</td>\n",
              "      <td>[This is EXACTLY what you want out of an actio...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>The action sequences in the JOHN WICK franchis...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.327083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does the level of violence in the third Jo...</td>\n",
              "      <td>[: 14\\nReview: By now you know what to expect ...</td>\n",
              "      <td>Based on the reviews provided, the level of vi...</td>\n",
              "      <td>The level of violence in the third John Wick f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.532738</td>\n",
              "      <td>0.650598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Who plays the character John Wick in the movie...</td>\n",
              "      <td>[John Wick (Reeves) is out to seek revenge on ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>Keanu Reeves plays the character John Wick in ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.415476</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What sets the Mission Impossible franchise apa...</td>\n",
              "      <td>[: 10\\nReview: Most American action flicks rel...</td>\n",
              "      <td>I don't know.</td>\n",
              "      <td>The Mission Impossible franchise is one of the...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.784722</td>\n",
              "      <td>0.181780</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  What makes the set pieces in John Wick: Chapte...   \n",
              "1  What sets the action sequences in the JOHN WIC...   \n",
              "2  How does the level of violence in the third Jo...   \n",
              "3  Who plays the character John Wick in the movie...   \n",
              "4  What sets the Mission Impossible franchise apa...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [: 18\\nReview: Ever since the original John Wi...   \n",
              "1  [This is EXACTLY what you want out of an actio...   \n",
              "2  [: 14\\nReview: By now you know what to expect ...   \n",
              "3  [John Wick (Reeves) is out to seek revenge on ...   \n",
              "4  [: 10\\nReview: Most American action flicks rel...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  The set pieces in John Wick: Chapter 4 stand o...   \n",
              "1  The action sequences in the JOHN WICK franchis...   \n",
              "2  Based on the reviews provided, the level of vi...   \n",
              "3  Keanu Reeves plays the character John Wick in ...   \n",
              "4                                      I don't know.   \n",
              "\n",
              "                                        ground_truth  context_recall  \\\n",
              "0  The answer to given question is not present in...             1.0   \n",
              "1  The action sequences in the JOHN WICK franchis...             1.0   \n",
              "2  The level of violence in the third John Wick f...             1.0   \n",
              "3  Keanu Reeves plays the character John Wick in ...             1.0   \n",
              "4  The Mission Impossible franchise is one of the...             0.5   \n",
              "\n",
              "   context_precision  answer_correctness  \n",
              "0           0.000000            0.924168  \n",
              "1           0.916667            0.327083  \n",
              "2           0.532738            0.650598  \n",
              "3           0.415476            1.000000  \n",
              "4           0.784722            0.181780  "
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_results_df = semantic_results.to_pandas()\n",
        "semantic_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_length = round(semantic_results_df['contexts'].apply(lambda x: len(str(x))).mean())\n",
        "\n",
        "semantic_avg_token_df = pd.DataFrame({'SemanticAvgToken': [avg_length]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SemanticAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SemanticAvgToken\n",
              "0              6488"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_avg_token_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "semantic_metrics_df = pd.DataFrame(list(semantic_results.items()), columns=['Metric', 'Semantic'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Semantic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.828431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.683538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.614006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Semantic\n",
              "0      context_recall  0.828431\n",
              "1   context_precision  0.683538\n",
              "2  answer_correctness  0.614006"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "dataframes = [baseline_metrics_df, contextual_compression_metrics_df, multi_query_metrics_df, parent_document_metrics_df, ensemble_metrics_df, semantic_metrics_df]\n",
        "\n",
        "\n",
        "merged_df = dataframes[0] \n",
        "\n",
        "for df in dataframes[1:]:\n",
        "    merged_df = pd.merge(merged_df, df, on='Metric', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>ContextualCompression</th>\n",
              "      <th>MultiQuery</th>\n",
              "      <th>ParentDoc</th>\n",
              "      <th>Ensemble</th>\n",
              "      <th>Semantic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.926471</td>\n",
              "      <td>0.818627</td>\n",
              "      <td>0.911765</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.828431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.739921</td>\n",
              "      <td>0.621724</td>\n",
              "      <td>0.672826</td>\n",
              "      <td>0.747549</td>\n",
              "      <td>0.606057</td>\n",
              "      <td>0.683538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.646322</td>\n",
              "      <td>0.633126</td>\n",
              "      <td>0.652217</td>\n",
              "      <td>0.629344</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.614006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  ContextualCompression  MultiQuery  ParentDoc  \\\n",
              "0      context_recall  0.926471               0.818627    0.911765   0.776961   \n",
              "1   context_precision  0.739921               0.621724    0.672826   0.747549   \n",
              "2  answer_correctness  0.646322               0.633126    0.652217   0.629344   \n",
              "\n",
              "   Ensemble  Semantic  \n",
              "0  0.916667  0.828431  \n",
              "1  0.606057  0.683538  \n",
              "2  0.688328  0.614006  "
            ]
          },
          "execution_count": 224,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Baseline</th>\n",
              "      <th>ContextualCompression</th>\n",
              "      <th>MultiQuery</th>\n",
              "      <th>ParentDoc</th>\n",
              "      <th>Ensemble</th>\n",
              "      <th>Semantic</th>\n",
              "      <th>HigestValue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.926471</td>\n",
              "      <td>0.818627</td>\n",
              "      <td>0.911765</td>\n",
              "      <td>0.776961</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.828431</td>\n",
              "      <td>0.93 (Baseline)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.739921</td>\n",
              "      <td>0.621724</td>\n",
              "      <td>0.672826</td>\n",
              "      <td>0.747549</td>\n",
              "      <td>0.606057</td>\n",
              "      <td>0.683538</td>\n",
              "      <td>0.75 (ParentDoc)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.646322</td>\n",
              "      <td>0.633126</td>\n",
              "      <td>0.652217</td>\n",
              "      <td>0.629344</td>\n",
              "      <td>0.688328</td>\n",
              "      <td>0.614006</td>\n",
              "      <td>0.69 (Ensemble)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric  Baseline  ContextualCompression  MultiQuery  ParentDoc  \\\n",
              "0      context_recall  0.926471               0.818627    0.911765   0.776961   \n",
              "1   context_precision  0.739921               0.621724    0.672826   0.747549   \n",
              "2  answer_correctness  0.646322               0.633126    0.652217   0.629344   \n",
              "\n",
              "   Ensemble  Semantic       HigestValue  \n",
              "0  0.916667  0.828431   0.93 (Baseline)  \n",
              "1  0.606057  0.683538  0.75 (ParentDoc)  \n",
              "2  0.688328  0.614006   0.69 (Ensemble)  "
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df['MaxValue'] = merged_df[['Baseline', 'ContextualCompression', 'MultiQuery', 'ParentDoc', 'Ensemble', 'Semantic']].max(axis=1)\n",
        "\n",
        "merged_df['MaxMetric'] = merged_df[['Baseline', 'ContextualCompression', 'MultiQuery', 'ParentDoc', 'Ensemble', 'Semantic']].idxmax(axis=1)\n",
        "\n",
        "merged_df['HigestValue'] = merged_df['MaxValue'].round(2).astype(str) + ' (' + merged_df['MaxMetric'] + ')'\n",
        "\n",
        "merged_df = merged_df.drop(columns=['MaxValue', 'MaxMetric'])\n",
        "\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_dfs = pd.concat([baseline_avg_token_df, contextual_compresion_avg_token_df, multi_query_avg_token_df, parent_doc_avg_token_df, ensemble_avg_token_df, semantic_avg_token_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BaslineAvgToken</th>\n",
              "      <th>CCAvgToken</th>\n",
              "      <th>MQAvgToken</th>\n",
              "      <th>PDAvgToken</th>\n",
              "      <th>EnsembleAvgToken</th>\n",
              "      <th>SemanticAvgToken</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9022</td>\n",
              "      <td>3898</td>\n",
              "      <td>10951</td>\n",
              "      <td>1350</td>\n",
              "      <td>16960</td>\n",
              "      <td>6488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   BaslineAvgToken  CCAvgToken  MQAvgToken  PDAvgToken  EnsembleAvgToken  \\\n",
              "0             9022        3898       10951        1350             16960   \n",
              "\n",
              "   SemanticAvgToken  \n",
              "0              6488  "
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_dfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the results of these evaluations and evaluating the average input token length along with the time to loop through the test_questions there are a few different strategies that could be considered the 'best' for this dataset. Looking at purely answer_correctness, the Ensemble retrieval method is best, however it did require the largest average length of input tokens which would then increase the cost of each query. Additionally, the time it took to answer each question came out to ~16 seconds (9 minutes total) if you consider the amount of time it took to loop through each question of the test_dataset. Considering the cost and time, perhaps the Ensemble method might not be the best despite it having the highest score when it comes to answer_correctness and high score of context_recall. When evaluating the RAGAS metric scores along with average token size and time per query, MultiQuery and the Baseline (Naive) retrieval methods are the two that stand out. Both have ~.92 context recall, much higher than Contextual Compression, ParentDoc, and Semantic and both have higher answer_correctness scores as well. They both do have larger average token amounts but considering the RAGAS metrics, the additional cost could be worth it. Further, \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
